{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#text\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# sklearn \n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "raw_train = train.copy()\n",
    "raw_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train,test],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Our Deeds are the Reason of this #earthquake M...\n",
       "1                   Forest fire near La Ronge Sask. Canada\n",
       "2        All residents asked to 'shelter in place' are ...\n",
       "3        13,000 people receive #wildfires evacuation or...\n",
       "4        Just got sent this photo from Ruby #Alaska as ...\n",
       "                               ...                        \n",
       "10871    EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
       "10872    Storm in RI worse than last hurricane. My city...\n",
       "10873    Green Line derailment in Chicago http://t.co/U...\n",
       "10874    MEG issues Hazardous Weather Outlook (HWO) htt...\n",
       "10875    #CityofCalgary has activated its Municipal Eme...\n",
       "Name: text, Length: 10876, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        our deeds are the reason of this earthquake ma...\n",
       "1                    forest fire near la ronge sask canada\n",
       "2        all residents asked to shelter in place are be...\n",
       "3         people receive wildfires evacuation orders in...\n",
       "4        just got sent this photo from ruby alaska as s...\n",
       "                               ...                        \n",
       "10871    earthquake safety los angeles ûò safety faste...\n",
       "10872    storm in ri worse than last hurricane my  hard...\n",
       "10873                    green line derailment in chicago \n",
       "10874            meg issues hazardous weather outlook hwo \n",
       "10875    cityofcalgary has activated its municipal emer...\n",
       "Name: text, Length: 10876, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['text'] = all_data['text'].map(lambda x : cleaning_text(x))\n",
    "all_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"fig, ax = plt.subplots(1,2,figsize=(15,10))\\nwordcloud1 = WordCloud().generate( ' '.join(all_data[all_data['target']==1]['text']) )\\nax[0].imshow(wordcloud1)\\nax[0].axis('off')\\nax[0].set_title('Real',fontsize=40)\\n\\nwordcloud2 = WordCloud().generate( ' '.join(all_data[all_data['target']==0]['text']) )\\nax[1].imshow(wordcloud2)\\nax[1].axis('off')\\nax[1].set_title('Fake',fontsize=40)\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''fig, ax = plt.subplots(1,2,figsize=(15,10))\n",
    "wordcloud1 = WordCloud().generate( ' '.join(all_data[all_data['target']==1]['text']) )\n",
    "ax[0].imshow(wordcloud1)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Real',fontsize=40)\n",
    "\n",
    "wordcloud2 = WordCloud().generate( ' '.join(all_data[all_data['target']==0]['text']) )\n",
    "ax[1].imshow(wordcloud2)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Fake',fontsize=40)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.RegexpTokenizer('\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        our deeds are the reason of this earthquake ma...\n",
       "1                    forest fire near la ronge sask canada\n",
       "2        all residents asked to shelter in place are be...\n",
       "3         people receive wildfires evacuation orders in...\n",
       "4        just got sent this photo from ruby alaska as s...\n",
       "                               ...                        \n",
       "10871    earthquake safety los angeles ûò safety faste...\n",
       "10872    storm in ri worse than last hurricane my  hard...\n",
       "10873                    green line derailment in chicago \n",
       "10874            meg issues hazardous weather outlook hwo \n",
       "10875    cityofcalgary has activated its municipal emer...\n",
       "Name: text, Length: 10876, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [our, deeds, are, the, reason, of, this, earth...\n",
       "1            [forest, fire, near, la, ronge, sask, canada]\n",
       "2        [all, residents, asked, to, shelter, in, place...\n",
       "3        [people, receive, wildfires, evacuation, order...\n",
       "4        [just, got, sent, this, photo, from, ruby, ala...\n",
       "                               ...                        \n",
       "10871    [earthquake, safety, los, angeles, ûò, safety,...\n",
       "10872    [storm, in, ri, worse, than, last, hurricane, ...\n",
       "10873               [green, line, derailment, in, chicago]\n",
       "10874      [meg, issues, hazardous, weather, outlook, hwo]\n",
       "10875    [cityofcalgary, has, activated, its, municipal...\n",
       "Name: text, Length: 10876, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['text'] = all_data['text'].map(lambda x : tokenizer.tokenize(x))\n",
    "all_data['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(word_list):\n",
    "    return [word for word in word_list if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [deeds, reason, earthquake, may, allah, forgiv...\n",
       "1            [forest, fire, near, la, ronge, sask, canada]\n",
       "2        [residents, asked, shelter, place, notified, o...\n",
       "3        [people, receive, wildfires, evacuation, order...\n",
       "4        [got, sent, photo, ruby, alaska, smoke, wildfi...\n",
       "                               ...                        \n",
       "10871    [earthquake, safety, los, angeles, ûò, safety,...\n",
       "10872    [storm, ri, worse, last, hurricane, hardest, h...\n",
       "10873                   [green, line, derailment, chicago]\n",
       "10874      [meg, issues, hazardous, weather, outlook, hwo]\n",
       "10875    [cityofcalgary, activated, municipal, emergenc...\n",
       "Name: text, Length: 10876, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['text'] = all_data['text'].map(lambda x : remove_stopwords(x))\n",
    "all_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_list(word_list):\n",
    "    return ' '.join(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             deeds reason earthquake may allah forgive us\n",
       "1                    forest fire near la ronge sask canada\n",
       "2        residents asked shelter place notified officer...\n",
       "3        people receive wildfires evacuation orders cal...\n",
       "4        got sent photo ruby alaska smoke wildfires pou...\n",
       "                               ...                        \n",
       "10871    earthquake safety los angeles ûò safety fasten...\n",
       "10872    storm ri worse last hurricane hardest hit yard...\n",
       "10873                        green line derailment chicago\n",
       "10874             meg issues hazardous weather outlook hwo\n",
       "10875    cityofcalgary activated municipal emergency pl...\n",
       "Name: text, Length: 10876, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['text'] = all_data['text'].map(lambda x : combine_list(x))\n",
    "all_data['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfrom Tokens to Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "train_vector = count_vectorizer.fit_transform(all_data.loc[:train.shape[0]-1,'text'])\n",
    "test_vector = count_vectorizer.transform(all_data.loc[train.shape[0]:,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 5), (3263, 4))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 16412), (3263, 16412))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vector.shape, test_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(min_df=2,max_df=0.5,ngram_range=(1,2))\n",
    "train_tf_vector = tf_vectorizer.fit_transform(all_data.loc[:train.shape[0]-1,'text'])\n",
    "test_tf_vector = tf_vectorizer.transform(all_data.loc[train.shape[0]:,'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 11077)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf_vector.todense().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5834476966398702"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LogisticRegression()\n",
    "model_selection.cross_val_score(model1,train_vector,train['target'],cv=5,scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5451346913743611"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_tf = LogisticRegression()\n",
    "model_selection.cross_val_score(model1_tf,train_tf_vector,train['target'],cv=5,scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6584930948850116"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = MultinomialNB()\n",
    "model_selection.cross_val_score(model2,train_vector,train['target'],cv=5,scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6187711183101462"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_tf = MultinomialNB()\n",
    "model_selection.cross_val_score(model2_tf,train_tf_vector,train['target'],cv=5,scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:40:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:40:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:40:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:40:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:40:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4526923263527385"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = xgb.XGBClassifier()\n",
    "model_selection.cross_val_score(model3,train_vector,train['target'],cv=5,scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:41:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:41:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:41:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:41:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:41:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44044956843219063"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3_tf = xgb.XGBClassifier()\n",
    "model_selection.cross_val_score(model3_tf,train_tf_vector,train['target'],cv=5,scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "model2.fit(train_vector,train['target'])\n",
    "submission['target'] = model2.predict(test_vector)\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
