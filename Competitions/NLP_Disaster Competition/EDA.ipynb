{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "raw_train = train.copy()\n",
    "raw_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatalities               45\n",
       "armageddon               42\n",
       "deluge                   42\n",
       "body%20bags              41\n",
       "damage                   41\n",
       "                         ..\n",
       "forest%20fire            19\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation%20emergency     9\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA                     104\n",
       "New York                 71\n",
       "United States            50\n",
       "London                   45\n",
       "Canada                   29\n",
       "                       ... \n",
       "Numenor                   1\n",
       "Montana                   1\n",
       "Bloomington, Indiana      1\n",
       "Lebanon, Tennessee        1\n",
       "The Canopy Kingdom        1\n",
       "Name: location, Length: 3341, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We always try to bring the heavy. #metal #RT http://t.co/YAo1e0xngw']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train[train['id']==49]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword                       location\n",
       "32  ablaze  Est. September 2012 - Bristol"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['id']==49][['keyword','location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                [3, 5, 3, 3, 6, 2, 4, 11, 3, 5, 7, 2, 3]\n",
       "1                                   [6, 4, 4, 2, 5, 5, 6]\n",
       "2       [3, 9, 5, 2, 8, 2, 6, 3, 5, 8, 2, 9, 2, 5, 10,...\n",
       "3                             [6, 6, 7, 10, 10, 6, 2, 10]\n",
       "4       [4, 3, 4, 4, 5, 4, 4, 7, 2, 5, 4, 10, 5, 4, 1, 6]\n",
       "                              ...                        \n",
       "7608                   [3, 5, 6, 7, 1, 6, 8, 4, 6, 5, 22]\n",
       "7609    [12, 12, 3, 3, 2, 7, 4, 5, 2, 10, 4, 2, 3, 8, ...\n",
       "7610                            [5, 6, 8, 1, 2, 7, 7, 22]\n",
       "7611    [6, 13, 5, 2, 6, 8, 4, 1, 3, 2, 6, 9, 6, 5, 8,...\n",
       "7612            [3, 7, 4, 5, 5, 2, 8, 10, 8, 1, 3, 4, 22]\n",
       "Name: text, Length: 3271, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_len =  train[train['target']==1]['text'].str.split().map(lambda word_list : [ len(word) for word in word_list])\n",
    "word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.384615384615385"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean( word_len[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Our, Deeds, are, the, Reason, of, this, #eart...\n",
       "1          [Forest, fire, near, La, Ronge, Sask., Canada]\n",
       "2       [All, residents, asked, to, 'shelter, in, plac...\n",
       "3       [13,000, people, receive, #wildfires, evacuati...\n",
       "4       [Just, got, sent, this, photo, from, Ruby, #Al...\n",
       "                              ...                        \n",
       "7608    [Two, giant, cranes, holding, a, bridge, colla...\n",
       "7609    [@aria_ahrary, @TheTawniest, The, out, of, con...\n",
       "7610    [M1.94, [01:04, UTC]?5km, S, of, Volcano, Hawa...\n",
       "7611    [Police, investigating, after, an, e-bike, col...\n",
       "7612    [The, Latest:, More, Homes, Razed, by, Norther...\n",
       "Name: text, Length: 3271, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['target']==1]['text'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@bbcmtd', 'Wholesale', 'Markets', 'ablaze', 'http://t.co/lHYXEOHY6C']\n"
     ]
    }
   ],
   "source": [
    "for word in train[train['id']==48]['text'].str.split():\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = feature_extraction.text.CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 54)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.fit_transform(train['text'][0:5])[0].todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Our',\n",
       " 'Deeds',\n",
       " 'are',\n",
       " 'the',\n",
       " 'Reason',\n",
       " 'of',\n",
       " 'this',\n",
       " '#earthquake',\n",
       " 'May',\n",
       " 'ALLAH',\n",
       " 'Forgive',\n",
       " 'us',\n",
       " 'all',\n",
       " 'Forest',\n",
       " 'fire',\n",
       " 'near',\n",
       " 'La',\n",
       " 'Ronge',\n",
       " 'Sask.',\n",
       " 'Canada']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for word_list in train['text'][[0,1]].str.split():\n",
    "    for word in word_list:\n",
    "        corpus.append(word)\n",
    "        \n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "plt.style.use('ggplot')\n",
    "stop=set(stopwords.words('english'))\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Our',\n",
       " 'Deeds',\n",
       " 'are',\n",
       " 'the',\n",
       " 'Reason',\n",
       " 'of',\n",
       " 'this',\n",
       " '#earthquake',\n",
       " 'May',\n",
       " 'ALLAH',\n",
       " 'Forgive',\n",
       " 'us',\n",
       " 'all',\n",
       " 'Forest',\n",
       " 'fire',\n",
       " 'near',\n",
       " 'La',\n",
       " 'Ronge',\n",
       " 'Sask.',\n",
       " 'Canada']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
